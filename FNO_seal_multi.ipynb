{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from torch.serialization import add_safe_globals\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import neuralop as nop\n",
    "from neuralop.models import FNO\n",
    "# from neuralop.layers.spectral_convolution import SpectralConv\n",
    "\n",
    "# add_safe_globals([torch._C._nn.gelu, SpectralConv])\n",
    "\n",
    "# 1. Load dataset.mat files\n",
    "data_dir = 'dataset/data/tapered_seal'\n",
    "mat_file = os.path.join(data_dir, '20250812_T_113003', 'dataset.mat')\n",
    "\n",
    "# 파라미터 설정\n",
    "batch_size = 2**10\n",
    "criterion = nop.losses.LpLoss(d=1, p=2)\n",
    "epochs = 1000\n",
    "param_embedding_dim = 64\n",
    "fno_modes = 16\n",
    "fno_hidden_channels = 128\n",
    "n_layers = 4\n",
    "shared_out_channels = fno_hidden_channels\n",
    "lr = 1e-3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "weight_decay=1e-4\n",
    "\n",
    "import json\n",
    "\n",
    "hyperparams = {\n",
    "    \"Batch size\": batch_size,\n",
    "    \"Parameter embedding dimension\": param_embedding_dim,\n",
    "    \"# of FNO modes\": fno_modes,\n",
    "    \"# of FNO hidden channels\": fno_hidden_channels,\n",
    "    \"# of FNO layers\": n_layers,\n",
    "    \"# of shared output channels\": shared_out_channels,\n",
    "    \"Learning rate\": f\"{lr:.1e}\"\n",
    "}\n",
    "\n",
    "print(json.dumps(hyperparams, indent=2))\n",
    "\n",
    "# 데이터 로딩 및 전처리\n",
    "with h5py.File(mat_file, 'r') as mat:\n",
    "    # inputNond: [nPara, nData] 형상 파라미터\n",
    "    input_nond = np.array(mat.get('inputNond'))\n",
    "    # wVec: [1, nVel] 회전 속도 벡터 (좌표 그리드)\n",
    "    w_vec = np.array(mat['params/wVec'])\n",
    "    # RDC: [6, nVel, nData] 동특성 계수 (타겟 함수)\n",
    "    rdc = np.array(mat.get('RDC'))\n",
    "\n",
    "    n_para, n_data = input_nond.shape\n",
    "    _, n_vel = w_vec.shape\n",
    "    n_rdc_coeffs = rdc.shape[0] # 6 (K, k, C, c, M, m)\n",
    "\n",
    "    # 입력 데이터 (X): 형상 파라미터 [nData, nPara]\n",
    "    X_params = input_nond.T\n",
    "\n",
    "    # 출력 데이터 (y): 동특성 계수 함수 [nData, nVel, nRDC]\n",
    "    # FNO는 (batch, channels, grid_points) 형태를 선호하므로 [nData, nRDC, nVel]로 변경이라고 GPT가 그럔다\n",
    "    y_functions = rdc.transpose(2, 0, 1) # [nData, nRDC, nVel]\n",
    "\n",
    "    # 회전 속도 그리드: [nVel, 1]\n",
    "    \n",
    "    w = w_vec.squeeze()                         # [n_vel]\n",
    "    w_norm = 2 * (w - w.min()) / (w.max()-w.min()) - 1.0 # normalization\n",
    "    grid = w_norm[:, None] # [nVel, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 스케일링\n",
    "# scaler_X = StandardScaler()\n",
    "# X_scaled = scaler_X.fit_transform(X_params) \n",
    "\n",
    "# scalers_y = [StandardScaler() for _ in range(n_rdc_coeffs)]\n",
    "# y_scaled_channels = []\n",
    "# for i in range(n_rdc_coeffs):\n",
    "#     # 각 채널(RDC)의 데이터를 [n_data * n_vel, 1] 형태로 만들어 스케일러에 적용\n",
    "#     channel_data = y_functions[:, i, :].reshape(-1, 1)\n",
    "#     scaled_channel_data = scalers_y[i].fit_transform(channel_data)\n",
    "#     # 원래 형태 [n_data, n_vel]로 복원\n",
    "#     y_scaled_channels.append(scaled_channel_data.reshape(n_data, n_vel))\n",
    "\n",
    "# # 스케일링된 채널들을 다시 [n_data, n_rdc_coeffs, n_vel]\n",
    "# y_scaled = np.stack(y_scaled_channels, axis=1)\n",
    "\n",
    "\n",
    "indices = np.arange(n_data)\n",
    "train_size = int(n_data*0.7); val_size = int(n_data*0.15)\n",
    "test_size = n_data - train_size - val_size\n",
    "train_idx, val_idx, test_idx = np.split(np.random.permutation(indices),\n",
    "                                        [train_size, train_size+val_size])\n",
    "\n",
    "scaler_X = StandardScaler().fit(X_params[train_idx])\n",
    "X_scaled = np.empty_like(X_params, dtype=float)\n",
    "X_scaled[train_idx] = scaler_X.transform(X_params[train_idx])\n",
    "X_scaled[val_idx]  = scaler_X.transform(X_params[val_idx])\n",
    "X_scaled[test_idx] = scaler_X.transform(X_params[test_idx])\n",
    "\n",
    "scalers_y = [StandardScaler().fit(y_functions[train_idx, i, :].reshape(-1,1))\n",
    "             for i in range(n_rdc_coeffs)]\n",
    "\n",
    "y_scaled = np.empty_like(y_functions, dtype=float)\n",
    "for i in range(n_rdc_coeffs):\n",
    "    for split_idx in (train_idx, val_idx, test_idx):\n",
    "        y_scaled[split_idx, i, :] = scalers_y[i].transform(\n",
    "            y_functions[split_idx, i, :].reshape(-1,1)\n",
    "        ).reshape(-1, y_functions.shape[-1])\n",
    "\n",
    "# Torch 텐서로 변환\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "# y_tensor = torch.tensor(y_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "grid_tensor = torch.tensor(grid, dtype=torch.float32)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.7)\n",
    "val_size = int(dataset_size * 0.15)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class ParametricFNO(nn.Module):\n",
    "    \"\"\"\n",
    "    기존: 형상 파라미터를 조건으로 받아 함수를 예측하는 FNO 모델 (단일 네트워크)\n",
    "    outputs: [B, out_channels, n_vel]\n",
    "    \"\"\"\n",
    "    def __init__(self, n_params, param_embedding_dim, fno_modes, fno_hidden_channels, in_channels, out_channels,n_layers):\n",
    "        super().__init__()\n",
    "        self.n_params = n_params\n",
    "        self.param_encoder = nn.Sequential(\n",
    "            nn.Linear(n_params, param_embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(param_embedding_dim, param_embedding_dim)\n",
    "        )\n",
    "        self.fno = FNO(\n",
    "            n_modes=(fno_modes,),\n",
    "            hidden_channels=fno_hidden_channels,\n",
    "            n_layers=n_layers,\n",
    "            in_channels=in_channels + param_embedding_dim,\n",
    "            out_channels=out_channels\n",
    "        )\n",
    "\n",
    "    def forward(self, params, grid):\n",
    "        # params: [B, n_params], grid: [B, n_vel, 1]\n",
    "        pe = self.param_encoder(params)                      # [B, emb]\n",
    "        pe = pe.unsqueeze(1).repeat(1, grid.shape[1], 1)    # [B, n_vel, emb]\n",
    "        fno_in = torch.cat([grid, pe], dim=-1).permute(0, 2, 1)  # [B, 1+emb, n_vel]\n",
    "        out = self.fno(fno_in)  # [B, out_channels, n_vel]\n",
    "        return out\n",
    "    \n",
    "class MultiHeadParametricFNO(nn.Module):\n",
    "    \"\"\"\n",
    "    FNO 본체는 공유하고, 채널별 1x1 Conv1d 헤드를 분리하는 멀티헤드 구조.\n",
    "    outputs: [B, n_heads(=n_rdc_coeffs), n_vel]\n",
    "    \"\"\"\n",
    "    def __init__(self, n_params, param_embedding_dim, fno_modes, fno_hidden_channels, in_channels, n_heads,n_layers, shared_out_channels):\n",
    "        super().__init__()\n",
    "        self.n_params = n_params\n",
    "        self.param_encoder = nn.Sequential(\n",
    "            nn.Linear(n_params, param_embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(param_embedding_dim, param_embedding_dim)\n",
    "        )\n",
    "        self.trunk = FNO(\n",
    "            n_modes=(fno_modes,),\n",
    "            hidden_channels=fno_hidden_channels,\n",
    "            n_layers=n_layers,\n",
    "            in_channels=in_channels + param_embedding_dim,\n",
    "            out_channels=shared_out_channels\n",
    "        )\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(shared_out_channels, shared_out_channels, 1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm1d(shared_out_channels),\n",
    "                nn.Dropout(0.1),\n",
    "                # depth 2\n",
    "                nn.Conv1d(shared_out_channels, shared_out_channels // 2, 1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm1d(shared_out_channels // 2),\n",
    "                nn.Dropout(0.1),\n",
    "                # output\n",
    "                nn.Conv1d(shared_out_channels // 2, 1, 1)\n",
    "            ) for _ in range(n_heads)\n",
    "        ])\n",
    "\n",
    "    def forward(self, params, grid):\n",
    "        pe = self.param_encoder(params)                       # [B, emb]\n",
    "        pe = pe.unsqueeze(1).repeat(1, grid.shape[1], 1)     # [B, n_vel, emb]\n",
    "        x = torch.cat([grid, pe], dim=-1).permute(0, 2, 1)   # [B, 1+emb, n_vel]\n",
    "        feat = self.trunk(x)                                  # [B, Csh, n_vel]\n",
    "        outs = [head(feat) for head in self.heads]            # each: [B,1,n_vel]\n",
    "        return torch.cat(outs, dim=1)                         # [B, n_heads, n_vel]\n",
    "\n",
    "optimizer = None\n",
    "best_val_loss = float('inf')\n",
    "base_dir = 'net'\n",
    "os.makedirs(base_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MultiHeadParametricFNO(\n",
    "    n_params=n_para,\n",
    "    param_embedding_dim=param_embedding_dim,\n",
    "    fno_modes=fno_modes,\n",
    "    fno_hidden_channels=fno_hidden_channels,\n",
    "    in_channels=1,\n",
    "    n_heads=n_rdc_coeffs,\n",
    "    n_layers=n_layers,\n",
    "    shared_out_channels=shared_out_channels\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "model_save_path = os.path.join(base_dir, 'fno_seal_best_multihead.pth')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train(); train_loss = 0.0\n",
    "    for params, functions in train_loader:\n",
    "        params, functions = params.to(device), functions.to(device)\n",
    "        batch_grid = grid_tensor.unsqueeze(0).repeat(params.size(0), 1, 1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(params, batch_grid)\n",
    "        loss = criterion(outputs, functions)\n",
    "        loss.backward(); optimizer.step()\n",
    "        train_loss += loss.item() * params.size(0)\n",
    "    model.eval(); val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for params, functions in val_loader:\n",
    "            params, functions = params.to(device), functions.to(device)\n",
    "            batch_grid = grid_tensor.unsqueeze(0).repeat(params.size(0), 1, 1).to(device)\n",
    "            outputs = model(params, batch_grid)\n",
    "            val_loss += criterion(outputs, functions).item() * params.size(0)\n",
    "    train_loss /= len(train_dataset); val_loss /= len(val_dataset)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train {train_loss:.6f}, Val {val_loss:.6f}')\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({'state_dict': model.state_dict()}, model_save_path)\n",
    "    scheduler.step()\n",
    "\n",
    "# --- Evaluate ---\n",
    "ckpt = torch.load(model_save_path, map_location=device, weights_only=False)\n",
    "sd = ckpt.get('state_dict', ckpt)\n",
    "sd.pop('_metadata', None) \n",
    "missing = model.load_state_dict(sd, strict=False)\n",
    "if missing.unexpected_keys:\n",
    "    print(\"unexpected:\", missing.unexpected_keys)\n",
    "if missing.missing_keys:\n",
    "    print(\"missing:\", missing.missing_keys)\n",
    "model.eval()\n",
    "\n",
    "n_test_samples = len(test_dataset.indices)\n",
    "test_params = X_tensor[test_dataset.indices].to(device)\n",
    "grid_repeated = grid_tensor.unsqueeze(0).repeat(n_test_samples, 1, 1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation on Test Set ---\n",
    "model.eval()\n",
    "test_params = X_tensor[test_dataset.indices].to(device)\n",
    "test_targets = y_tensor[test_dataset.indices].to(device)\n",
    "grid_repeated = grid_tensor.unsqueeze(0).repeat(len(test_dataset.indices), 1, 1).to(device)\n",
    "\n",
    "with torch.no_grad(): # 예측하는 부분인듯\n",
    "    preds_scaled = model(test_params, grid_repeated).cpu().numpy()\n",
    "    targets_scaled = test_targets.cpu().numpy()\n",
    "\n",
    "preds_tmp, targets_tmp = [], []\n",
    "for i in range(n_rdc_coeffs):\n",
    "    preds_tmp.append(  scalers_y[i].inverse_transform(preds_scaled[:, i, :]) )\n",
    "    targets_tmp.append(scalers_y[i].inverse_transform(targets_scaled[:, i, :]) )\n",
    "\n",
    "preds_orig   = np.stack(preds_tmp,   axis=1)\n",
    "targets_orig = np.stack(targets_tmp, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 시각화\n",
    "import matplotlib.colors as mcolors\n",
    "mcolors_list = list(mcolors.TABLEAU_COLORS.values())  # HEX 값 리스트\n",
    "# mcolors_list = list(mcolors.CSS4_COLORS.values())  # HEX 값 리스트\n",
    "rdc_labels = ['K', 'k', 'C', 'c', 'M', 'm']\n",
    "rdc_units = ['N/m', 'N/m', 'N s/m', 'N s/m', 'kg', 'kg']\n",
    "    \n",
    "n_plot = 5\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 14))\n",
    "axes = axes.flatten()  # 2D -> 1D 배열로 변환\n",
    "\n",
    "for j in range(n_rdc_coeffs):\n",
    "    ax = axes[j]\n",
    "    for idx in range(n_plot):\n",
    "        color = mcolors_list[idx % len(mcolors_list)]\n",
    "        ax.plot(w, targets_orig[idx, j, :], color=color, linestyle='-', \n",
    "                label=f\"True, #{test_dataset.indices[idx]}\")\n",
    "        ax.plot(w, preds_orig[idx, j, :], color=color, linestyle='--', marker='o', markersize=3, \n",
    "                label=f\"Pred, #{test_dataset.indices[idx]}\")\n",
    "    ax.set_xlabel('Rotational speed [rad/s]')\n",
    "    ax.set_ylabel(f\"{rdc_units[j]}\")\n",
    "    ax.set_title(f\"{rdc_labels[j]}\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout(rect=(0, 0.03, 1, 0.96))\n",
    "plt.show()\n",
    "\n",
    "# n_plot = 5\n",
    "# for j in range(n_rdc_coeffs):\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     for idx in range(n_plot):\n",
    "#         color = mcolors_list[idx % len(mcolors_list)] \n",
    "#         plt.plot(w, targets_orig[idx,j,:], color=color, linestyle='-', label=f\"True, #{test_dataset.indices[idx]}\")\n",
    "#         plt.plot(w, preds_orig[idx,j,:], color=color, linestyle='--', marker='o', markersize=3, label=f\"Pred, #{test_dataset.indices[idx]}\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.xlabel('Rotational speed [rad/s]')\n",
    "#     plt.ylabel(f\"{rdc_units[j]}\")\n",
    "#     plt.title(f\"{rdc_labels[j]}\")\n",
    "#     plt.tight_layout(rect=(0, 0.03, 1, 0.96)); plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "for coeff_idx, label in enumerate(rdc_labels):\n",
    "    y_true = np.ravel(targets_orig[:, coeff_idx, :])\n",
    "    y_pred = np.ravel(preds_orig[:, coeff_idx, :])\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    yrng = (y_true.max() - y_true.min())\n",
    "    rrmse = rmse / (yrng + 1e-12)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + 1e-12)))\n",
    "\n",
    "    print(f\"[{label}] RMSE: {rmse:.6g}, MAE: {mae:.6g}, \"\n",
    "          f\"R^2: {r2:.6f}, rRMSE: {100*rrmse:.4f}%, MAPE: {100*mape:.4f}%\")\n",
    "\n",
    "# 전체 지표\n",
    "y_true_all = np.ravel(targets_orig)\n",
    "y_pred_all = np.ravel(preds_orig)\n",
    "mse = mean_squared_error(y_true_all, y_pred_all)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true_all, y_pred_all)\n",
    "r2 = r2_score(y_true_all, y_pred_all)\n",
    "yrng = (y_true_all.max() - y_true_all.min())\n",
    "rrmse = rmse / (yrng + 1e-12)\n",
    "mape = np.mean(np.abs((y_true_all - y_pred_all) / (np.abs(y_true_all) + 1e-12)))\n",
    "\n",
    "print(f\"[Overall] RMSE: {rmse:.6g}, MAE: {mae:.6g}, \"\n",
    "      f\"R^2: {r2:.6f}, rRMSE: {100*rrmse:.4f}%, MAPE: {100*mape:.4f}%\")\n",
    "\n",
    "import time\n",
    "\n",
    "model.eval()\n",
    "test_params = X_tensor[test_dataset.indices].to(device)\n",
    "test_targets = y_tensor[test_dataset.indices].to(device)\n",
    "grid_repeated = grid_tensor.unsqueeze(0).repeat(len(test_dataset.indices), 1, 1).to(device)\n",
    "\n",
    "# 예측 시간 측정\n",
    "with torch.no_grad():\n",
    "    torch.cuda.synchronize()  # GPU 시간 측정 전 동기화\n",
    "    start_time = time.time()\n",
    "\n",
    "    preds_scaled = model(test_params, grid_repeated)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "print(f\"Inference time for {len(test_dataset)} samples: {end_time - start_time:.6f} seconds\")\n",
    "print(f\"Average per sample: {(end_time - start_time)/len(test_dataset):.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
